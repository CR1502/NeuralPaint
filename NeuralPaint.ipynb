{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk(\"../input/art-portraits/Portraits/\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nnp.random.seed(42)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Libraries\n\nimport random\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\nfrom PIL import Image\nimport tensorflow  as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Reshape, UpSampling2D, Conv2D, BatchNormalization\nfrom tensorflow.keras.layers import LeakyReLU, Dropout, ZeroPadding2D, Flatten, Activation\nfrom tensorflow.keras.optimizers import Adam\nimport tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Settings\n\nsns.set(rc={\"axes.facecolor\":\"#EDE9DE\",\"figure.facecolor\":\"#D8CA7E\"})","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing data\n\ndata_path = \"../input/art-portraits/Portraits/\"\nbatch_s = 64\n\n# Import as tf.Dataset\ndata = tf.keras.preprocessing.image_dataset_from_directory(data_path, label_mode = None, image_size = (64,64), batch_size = batch_s)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining a function to see images\n\ndef Show_Img(data):\n    plt.figure(figsize=(15,15))\n    for images in data.take(1):\n        for i in range(18):\n            ax = plt.subplot(6, 6, i + 1)\n            ax.imshow(images[i].numpy().astype(\"uint8\"))\n            ax.axis(\"off\")\n            \n# Plotting the images in dataset     \n\nShow_Img(data)","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing the dataset for model\n\ndata = data.map(lambda x: x / 255.0)\ndata","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g_resolution=2\n\n# Building a Generator\n\ngenerator = Sequential()\ngenerator.add(Dense(4*4*256,activation=\"relu\",input_dim=100))\ngenerator.add(Reshape((4,4,256)))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(256,kernel_size=3,padding=\"same\"))#\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(128,kernel_size=3,padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(Conv2D(3,kernel_size=3,padding=\"same\"))\ngenerator.add(Activation(\"tanh\"))\n\ngenerator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a random seed and output from generator\n\nseed = tf.random.normal([1, latent_dim])\nGenerated_Portrait = generator(seed, training=False)\n\n# Plotting the image output of generator without training \n\nplt.imshow(Generated_Portrait[0, :, :, 0])\nplt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building a Discriminator\n\ndiscriminator = Sequential()\ndiscriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(64,64,3), padding=\"same\"))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\ndiscriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(1, activation=\"sigmoid\"))\n\ndiscriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For the random image generated\n\nDiscriminator_Verdict = discriminator(Generated_Portrait)\nprint (Discriminator_Verdict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAN(tf.keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def train_step(self, real_images):\n        batch_size = tf.shape(real_images)[0]\n        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n        generated_images = self.generator(seed)\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n        \n        # Train the discriminator\n        \n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n\n        # Sample random points in the latent space\n         \n        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        \n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator!\n         \n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(seed))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Update metrics\n        \n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the number of epochs\n\nepochs = 200\n\n#The optimizers for Generator and Discriminator\n\ndiscriminator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\ngenerator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\n\n# To compute cross entropy loss\n\nloss_fn = tf.keras.losses.BinaryCrossentropy()\n\n# Defining GAN Model\n\nmodel = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n\n# Compiling GAN Model\n\nmodel.compile(d_optimizer=discriminator_opt, g_optimizer=generator_opt, loss_fn=loss_fn)\n\n# Fitting the GAN\n\nhistory = model.fit(data, epochs=epochs)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pal=[\"#994F5F\",\"#E2AB30\"]\n\n# Plotting the learning curve\n\nhistory_df = pd.DataFrame(history.history)\nfig = plt.figure(figsize=(15,4))\nax=sns.lineplot(data=history_df, palette= pal)\nax.set(xlabel =\"Epochs\")\nax.set(ylabel =\"Loss\")\nax.set_title(\"Learning Curve\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images to be generate\n\nnum_img=18\n\n# A function to generate and save images\n\ndef Potrait_Generator():\n    Generated_Paintings = []\n    seed = tf.random.normal([num_img, latent_dim])\n    generated_image = generator(seed)\n    generated_image *= 255 \n    generated_image = generated_image.numpy()\n    for i in range(num_img):\n            img = tf.keras.preprocessing.image.array_to_img(generated_image[i])\n            Generated_Paintings.append(img)\n            img.save(\"Potraits{:02d}.png\".format(i)) \n    return \n\n# Generating images\nImages = Potrait_Generator()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading generated images\n\nGenerated_path = \"./\"\nPotraits_generated = tf.keras.preprocessing.image_dataset_from_directory(Generated_path, label_mode = None)\n\n# Plotting generated images\n\nShow_Img(Potraits_generated)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}